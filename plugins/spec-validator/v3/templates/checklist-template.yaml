# Spec Implementation Checklist
# Generated by spec-validator plugin
# This file tracks implementation progress against the specification

# === METADATA ===
metadata:
  spec_file: "[SPEC_FILE_PATH]"
  project_name: "[PROJECT_NAME]"
  created_date: "[CREATED_DATE]"
  last_updated: "[LAST_UPDATED]"
  checklist_version: "1.0.0"

# === FUNCTIONAL REQUIREMENTS ===
# Status: completed | in_progress | not_started | blocked
# Test Status: completed | in_progress | not_started
# Priority: high | medium | low

functional_requirements:
  # Template will generate entries like this for each FR in spec:
  # - id: "FR-1"
  #   title: "User authentication with email and password"
  #   priority: "high"
  #   status: "not_started"
  #   test_status: "not_started"
  #   implementation_notes: ""
  #   blockers: ""
  #   completed_date: null
  #   tests:
  #     unit: "not_started"
  #     integration: "not_started"
  #     e2e: "not_started"
[FUNCTIONAL_REQUIREMENTS_ENTRIES]

# Example FR entry (remove this in actual implementation):
# - id: "FR-1"
#   title: "User authentication with email and password"
#   priority: "high"
#   status: "completed"
#   test_status: "completed"
#   implementation_notes: "Implemented using JWT tokens. Session expires after 24h."
#   blockers: ""
#   completed_date: "2026-02-10"
#   tests:
#     unit: "completed"
#     integration: "completed"
#     e2e: "completed"

# === NON-FUNCTIONAL REQUIREMENTS ===

non_functional_requirements:
  # Template will generate entries like this for each NFR in spec:
  # - id: "NFR-1"
  #   title: "API response time under 200ms"
  #   status: "not_started"
  #   test_status: "not_started"
  #   implementation_notes: ""
  #   blockers: ""
  #   completed_date: null
[NON_FUNCTIONAL_REQUIREMENTS_ENTRIES]

# Example NFR entry:
# - id: "NFR-1"
#   title: "API response time under 200ms for 95th percentile"
#   status: "in_progress"
#   test_status: "in_progress"
#   implementation_notes: "Currently at 250ms. Optimizing database queries."
#   blockers: "Need to add Redis caching layer"
#   completed_date: null

# === DATA MODELS ===

data_models:
  # Template will generate entries like this for each model in spec:
  # - name: "User"
  #   status: "not_started"
  #   implementation_notes: ""
  #   fields_implemented: []
  #   fields_pending: []
[DATA_MODELS_ENTRIES]

# Example model entry:
# - name: "User"
#   status: "completed"
#   implementation_notes: "Implemented in models/user.py with SQLAlchemy ORM"
#   fields_implemented:
#     - id
#     - email
#     - password_hash
#     - created_at
#     - updated_at
#   fields_pending: []

# === API ENDPOINTS ===

api_endpoints:
  # Template will generate entries like this for each endpoint in spec:
  # - method: "POST"
  #   path: "/api/auth/login"
  #   status: "not_started"
  #   test_status: "not_started"
  #   implementation_notes: ""
  #   blockers: ""
[API_ENDPOINTS_ENTRIES]

# Example API entry:
# - method: "POST"
#   path: "/api/auth/login"
#   status: "completed"
#   test_status: "completed"
#   implementation_notes: "Implemented in auth_controller.py. Returns JWT token."
#   blockers: ""

# === EDGE CASES ===

edge_cases:
  # Template will generate entries like this for each edge case in spec:
  # - id: "EC-1"
  #   description: "Handle duplicate email registration attempts"
  #   status: "not_started"
  #   test_status: "not_started"
  #   implementation_notes: ""
[EDGE_CASES_ENTRIES]

# Example edge case entry:
# - id: "EC-1"
#   description: "Handle duplicate email registration attempts"
#   status: "completed"
#   test_status: "completed"
#   implementation_notes: "Returns 409 Conflict with appropriate error message"

# === VALIDATION HISTORY ===
# Automatically updated by spec-validator plugin
# Do not manually edit this section

validation_history: []
  # Example entry (will be auto-populated):
  # - date: "2026-02-13T10:30:00Z"
  #   score: 75
  #   grade: "C"
  #   dimensions:
  #     completeness: 28
  #     quality: 18
  #     adherence: 17
  #     transparency: 12
  #   mode: "full"
  #   validator_version: "1.0.0"

# === NOTES ===

# How to use this checklist:
# 1. Update status fields as you implement features
# 2. Add implementation_notes to document decisions and context
# 3. Mark blockers explicitly so they're visible in validation reports
# 4. Update test_status separately from implementation status
# 5. Run validation periodically: /validate or "validate spec implementation"
# 6. Aim for score >= 90 before releasing

# Status definitions:
# - not_started: Not yet begun
# - in_progress: Actively being worked on
# - completed: Fully implemented and tested
# - blocked: Cannot proceed due to dependencies or issues

# Test status definitions:
# - not_started: No tests written yet
# - in_progress: Some tests written, coverage incomplete
# - completed: Fully tested with passing tests

# Priority guidelines (for FRs):
# - high: Critical for MVP, blocks other features
# - medium: Important but not blocking
# - low: Nice to have, can be deferred

---

## Template Generation Instructions

To generate a checklist from a spec:

1. Parse the spec document to extract all requirements
2. Read this template file
3. Replace [FUNCTIONAL_REQUIREMENTS_ENTRIES] with generated FR entries
4. Replace [NON_FUNCTIONAL_REQUIREMENTS_ENTRIES] with generated NFR entries
5. Replace [DATA_MODELS_ENTRIES] with generated model entries
6. Replace [API_ENDPOINTS_ENTRIES] with generated API entries
7. Replace [EDGE_CASES_ENTRIES] with generated edge case entries
8. Replace metadata placeholders:
   - [SPEC_FILE_PATH] → path to spec file
   - [PROJECT_NAME] → extracted from spec or user input
   - [CREATED_DATE] → current date in YYYY-MM-DD format
   - [LAST_UPDATED] → current date in YYYY-MM-DD format
9. Write the populated content to .spec-checklist.yaml

Entry format for each section:

Functional Requirements:
```yaml
  - id: "[FR-ID]"
    title: "[FR-TITLE]"
    priority: "[PRIORITY]"  # high/medium/low
    status: "not_started"
    test_status: "not_started"
    implementation_notes: ""
    blockers: ""
    completed_date: null
    tests:
      unit: "not_started"
      integration: "not_started"
      e2e: "not_started"
```

Non-Functional Requirements:
```yaml
  - id: "[NFR-ID]"
    title: "[NFR-TITLE]"
    status: "not_started"
    test_status: "not_started"
    implementation_notes: ""
    blockers: ""
    completed_date: null
```

Data Models:
```yaml
  - name: "[MODEL-NAME]"
    status: "not_started"
    implementation_notes: ""
    fields_implemented: []
    fields_pending: []
```

API Endpoints:
```yaml
  - method: "[HTTP-METHOD]"  # GET/POST/PUT/DELETE/PATCH
    path: "[API-PATH]"
    status: "not_started"
    test_status: "not_started"
    implementation_notes: ""
    blockers: ""
```

Edge Cases:
```yaml
  - id: "[EC-ID]"
    description: "[EDGE-CASE-DESCRIPTION]"
    status: "not_started"
    test_status: "not_started"
    implementation_notes: ""
```
