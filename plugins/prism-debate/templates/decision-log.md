# Decision Log

> AI prediction tracking — Layer 4 of the 5-Layer Quality System.
> Each entry is an AI-assisted decision with a verifiable prediction and a future review date.
> Review entries on their due dates and record actual outcomes to measure AI accuracy over time.

---

## How to Use

1. After each `/think-deep` session, choose "기록하기" to append the suggested entry
2. On the review date, return to the entry and fill in "Actual Outcome" and "Accuracy"
3. After 10+ entries, look for patterns: which question types does AI handle well? Poorly?

---

## Log

| Date | Question | Verdict | Prediction | Review Date | Actual Outcome | Accuracy |
|------|----------|---------|------------|-------------|----------------|----------|
| YYYY-MM-DD | {question summarized} | [RECOMMEND] | {specific measurable prediction} | YYYY-MM-DD | — | — |

---

## Accuracy Tracking

> Fill in after review dates pass.

| Question Type | Total | Correct | Accuracy |
|---------------|-------|---------|----------|
| Architecture / technical | 0 | 0 | — |
| Career / strategy | 0 | 0 | — |
| Market / timing | 0 | 0 | — |
| Risk assessment | 0 | 0 | — |
| Learning / skill decisions | 0 | 0 | — |

---

## Patterns Observed

> Add notes as patterns emerge over time.

- {date}: AI tends to underestimate X when Y...
- {date}: AI's [FACT]-labeled claims have been accurate N/M times
